# 5. Addressing the elephant in the room

As we discussed in [When does carbon-aware software make sense?](when-does-carbon-aware-make-sense.md), the key challenge for greening computing is not optimisation but electricity demand. We think that carbon aware computing, if it is to fulfill its potential and promise, needs to directly engage with this reality.

Our two refined and proposed carbon-aware approaches don’t stand to gain us much if we are not also tackling the big question: **how much of the world’s resources is it acceptable for tech to use?**

There is a danger that the key takeaway from proposals 1 and 2, is that if we build and run electricity and data centres more innovatively, we can safely continue with business as usual. We can safely build massive AI products, keep growing our data centres and enjoy the benefits of limitless personal compute potential as long as we are targetting the growing renewable energy resources at low demand times.

<a href="https://www.iea.org/reports/electricity-market-report-2023/executive-summary">70% of all electricity still comes from fossil fuels which will reduce to 65% in 2025.</a> This is encouraging, but there is no short or medium term scenario in which targetting curtailed renewable energy could power our global compute. There is also no scenario where additive purchases or direct renewable provision could grow at the speed required to catch up and keep up with rising compute demand in time to affect significantly our global warming trajectory. 

It cannot be understated that one of the biggest shifts required to reduce carbon emissions in line with the <a href="https://en.wikipedia.org/wiki/Paris_Agreement">Paris Agreement</a> is to accept that we cannot continue to grow everything without some constraints. At least not in the short-term whilst we wildly exceed the world’s carbon budgets and need to drastically reduce our emissions. The need to manage growth would remain even if we completely switched entirely to renewables: <a href="https://www.mdpi.com/2079-9276/8/1/29">we would run out of the minerals and metals we would needto keep up with current energy demand growth rates</a> 

### Proposal 3: Demand shaping computing electricity use so it stays within agreed resource use boundaries

> **TL;DR:** The core question that should be on all responsible technologists’ minds: **is my compute’s net electricity demand reducing, or at least slowing its rate of increase?** This is a question that can be addressed at the indivdidual, company, national and international level. 

#### The global emissions picture

The tech industry is caught between the commercial imperative for growth, and the business as well as global costs and risks of accelerating global warming. Beyond the polarities of growth vs degrowth, what must surely be accepted is that unlimited growth is unviable for our industry and for our planet. Whatever the boundaries of the debate, we need to accept there should be limits to the net resources consumed by our sector, not just to how energy-efficiently we consume them. 


> “The current emissions from computing are about 2% of the world total but are projected to rise steeply over the next two decades. By 2040 emissions from computing alone will be more than half the emissions level acceptable to keep global warming below 1.5°C. This growth in computing emissions is unsustainable: it would make it virtually impossible to meet the emissions warming limit. Plus, the emissions from the production of computing devices far exceed the emissions from operating them. So, even if software is more energy efficient, producing more of them will make the emissions problem worse.” 
>
> <a href="https://www.dcs.gla.ac.uk/~wim//low-carbon-computing/index.html">Low carbon and sustainable computing</a>, by Professor Wim Vanderbauwhede

<a href="https://docs.google.com/spreadsheets/d/e/2PACX-1vSd8nYugza3UjPaG8Y6DP8Fufq4JxWDDn8cdSQXq7KyfeXkbLvc3XC9uDxyXr5dkA/pubhtml">Two models created for this article by Professor Vanderbauwhede</a> show that the real problem our planet faces is not how we optimise our compute via patterns like carbon-aware compute, but how we change the alarming growth trend in computing driven electricity demand. 

The first model shows that because carbon-aware computing does not assume energy demand reduction, only greener compute whatever the demand, it will hardly slow down our race to <a href="https://en.wikipedia.org/wiki/Tipping_points_in_the_climate_system">planetary tipping points</a>.

Business as usual (BAU) would mean an 800% increase in computer-related electricty demand by 2040, and a 310% increase in our sector's emissions by 2040 - most of the planet's carbon budget. 

At current computing demand growth rates, implementing carbon-aware computing with the adjustments we propose, by 20240 computing-related emissions would rise by 280%. Every single reduction counts and buys us days, months, years before irreversible milestones, so that 20% difference matters. But it still spells disaster. Like placing a bandaid on a serious wound.

In contrast, demand reduction has an exponential effect. if our sector continued to grow, but managed to limit that growth to 26% between now and 2040, our computer-related emissions that year would be 50% of what they are today, accounting for the rise in renewables. With our proposed carbon aware improvements, the emissions savings would be 56%. In this scenario, our improved carbon-aware computing might be not a bandaid, but one of the ingredients of a genuine solution to our sector and our planet's environmental challenge. 

This goes back to our call for more holistic, long term, systemic thinking on the relationship between computing and the increasingly decarbonising energy grid, where demand response mechanisms will become increasingly necessary, as well as the opportunities of distributed computing and distributed energy systems to at least complement the predominant centralised model of massive data centres and power plants.

Fundamentally, what we are calling for is for some innovative backcasting, that can translate the global carbon budget into a tech energy budget, over a critical timeline, and identify the innovations, integrations and optimisations needed to not just operate but thrive in those scenarios. 

Carbon aware computing implies a wider vision of the relationship between emissions and electricity demand, consumption, generation and management. The event-driven architecture of our early implementations is a great foundation on which to build. The refinements we offer in proposals 1 and 2 may mitigate the risks and optimise the benefits. But there is also an opportunity to think bigger, into how we implement, expand and evolve such patterns at scale with key energy and policy partners in a way that not just optimises our emissions, but reduces net consumption in a fair and equitable way across all nations. The concept of improved carbon-aware computing could be hugely helpful. 

If this article sparks a conversation on what these patterns could look like for data centres, for AI, for blockchains, and indeed for power plants, for renewable energy providers and infrastructure vendors, for investors and regulators, there is no doubt that breakthroughs would follow.




## Next section
Continue the journey: [Where do we take carbon-aware from here? Introducing grid-aware computing](grid-aware-computing.md)