# 5. Addressing the elephant in the room

And lastly, our two refined and approved carbon-aware approaches don’t stand to gain us much if we are not also tackling the big question: **how much of the world’s resources is it acceptable for tech to use?**

There is a danger that the key takeaway from ways 1 and 2, is that if we build and use electricity and data centres more innovatively, we can safely continue with business as usual. We can build massive AI products, keep growing our data centres and enjoy the benefits of limitless personal compute potential.

It cannot be understated that one of the biggest shifts required to reduce carbon emissions in line with the <a href="https://en.wikipedia.org/wiki/Paris_Agreement">Paris Agreement</a> is to accept that we cannot continue to grow everything without some limitations. At least not in the short-term whilst we wildly exceed the world’s carbon budgets and need to drastically reduce our emissions. 

### Way 3: Demand shaping computing electricity use so it stays within agreed resource use boundaries

> **TL;DR:** The core question that should be on all responsible technologists’ minds: is my compute’s net electricity demand reducing?  Data centres should interact with grids and seek assent to use electricity or other resources in a dynamic way, against a specific resource budget. 

#### The global emissions picture

As a digital tech industry level, we need to accept there should be limits to the amount of resources consumed. To achieve this we have to look at and restrict the growth of computing. Many would argue this is where the real, impactful work lies.

> “The current emissions from computing are about 2% of the world total but are projected to rise steeply over the next two decades. By 2040 emissions from computing alone will be more than half the emissions level acceptable to keep global warming below 1.5°C. This growth in computing emissions is unsustainable: it would make it virtually impossible to meet the emissions warming limit. Plus, the emissions from the production of computing devices far exceed the emissions from operating them. So, even if software is more energy efficient, producing more of them will make the emissions problem worse.” 
>
> <a href="https://www.dcs.gla.ac.uk/~wim//low-carbon-computing/index.html">Low carbon and sustainable computing</a>, by Professor Wim Vanderbauwhede

<a href="https://docs.google.com/spreadsheets/d/e/2PACX-1vSd8nYugza3UjPaG8Y6DP8Fufq4JxWDDn8cdSQXq7KyfeXkbLvc3XC9uDxyXr5dkA/pubhtml">Two models created for this article by Professor Vanderbauwhede</a> show that the real problem our planet faces is not how we optimise our compute via patterns like carbon-aware compute, but how we change the alarming growth trend in computing driven electricity demand. 

The first model shows that because carbon-aware computing does not assume energy demand reduction, only greener compute whatever the demand, it will hardly slow down our race to <a href="https://en.wikipedia.org/wiki/Tipping_points_in_the_climate_system">planetary tipping points</a>.

Business as usual results in a 3 times increase in emissions by 2040 - most of the planet's carbon budget. With the adjustments to carbon-aware computing in scenarios 1 and 2, it will be 2.8 times. That 0.2 factor does matter. Every single reduction counts and buys us days, months, years before irreversible milestones. But it is hardly the solution. 

The second model shows that specifically the reductions from location shifting are very modest. Even if there were no issues with demand, capacity and curtailment, realistic scenarios give around 3% reductions in emissions generated by computing electricity use. This is because of the overhead in location shifting and the embodied carbon of the required excess capacity.

In contrast, if we achieved a 50% reduction in computing related electricity demand, the increase in emissions by 2050 would be 0.2 times; and combined with grid-aware computing, 0.18 times. In this scenario, grid-aware computing might be not a bandaid, but a small but definite element in some form of homeostasis: true sustainability. 

One course of action is to prioritise where our resource usage goes and make sure it happens in a fair and equitable way across all nations. The concept of improved carbon-aware computing could be hugely helpful. Especially so if data centres interact with grids and seek assent to use electricity or other resources in a dynamic way, as we described above, but against a specific budget. We touched on this in scenario 1 as well.
What those budgets should be, and for what types of compute activity will require some thought. Nevertheless, this is a vital step to put checks and balances in place to shape computing’s demand and ensure the basic human needs of a local population are met before the profits of Big Tech.


#### Data centres are considered "critical infrastructure"

A hurdle we have to overcome when implementing something like this is that right now, data centres are considered "critical infrastructure", whatever type of compute they're running. This means they automatically get preferential access to the grid. When grid operators are deciding who to provide power to at times of strain, they often receive priority the same way hospitals might as well.

This is also partly why in West London in 2022, <a href="https://www.datacenterdynamics.com/en/news/report-home-building-to-halt-in-west-london-due-to-data-center-power-demands/">datacentres were able to get grid access ahead of the construction of new houses</a>.

It's possible to flip it around so the default is that data centres only pull power from the grid when there is excess green energy that needs to be used. In this scenario, it's likely big operators would just source their own local off-grid power, which is almost universally more co2 emitting because year round onsite power usually relies on fossil fuels.


## Next section
Continue the journey: [Where do we take carbon-aware from here? Introducing grid-aware computing](grid-aware-computing.md)